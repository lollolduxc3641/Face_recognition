import cv2
import torch
import numpy as np
from torchvision import models, transforms
from picamera2 import Picamera2
from pathlib import Path
from numpy.linalg import norm

# H√†m cosine similarity
def cosine_similarity(a, b):
    return np.dot(a, b) / (norm(a) * norm(b))

# Th√¥ng tin
# === ƒê·ªìng b·ªô ƒë∆∞·ªùng d·∫´n ===
user_name = "KHOI"
base_dir = Path(__file__).resolve().parent.parent  # => face_auth/
embedding_path = base_dir / "data" / user_name / "embeddings.npy"
haar_path = base_dir / "haar" / "haarcascade_frontalface_default.xml"

# Load d·ªØ li·ªáu
if not Path(embedding_path).exists():
    print("‚ùå embeddings.npy ch∆∞a t·ªìn t·∫°i. Ch·∫°y extract_all_embeddings.py tr∆∞·ªõc.")
    exit()

embeddings = np.load(embedding_path)

# Model
model = models.mobilenet_v2(pretrained=True)
model.classifier = torch.nn.Identity()
model.eval()

# Transform ·∫£nh
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# Haar
face_cascade = cv2.CascadeClassifier(haar_path)

# Camera
picam2 = Picamera2()
picam2.configure(picam2.create_preview_configuration(main={"format": 'XRGB8888', "size": (640, 480)}))
picam2.start()

cv2.namedWindow("Ki·ªÉm tra kho·∫£ng c√°ch", cv2.WINDOW_NORMAL)
cv2.resizeWindow("Ki·ªÉm tra kho·∫£ng c√°ch", 600, 350)

print("üì∏ Nh·∫•n SPACE ƒë·ªÉ ki·ªÉm tra, ESC ƒë·ªÉ tho√°t.")

while True:
    frame = picam2.capture_array()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    cv2.imshow("Ki·ªÉm tra kho·∫£ng c√°ch", frame)

    key = cv2.waitKey(1)
    if key == 27:
        break
    elif key == 32:
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)

        if len(faces) == 0:
            print("‚ùå Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t.")
            continue

        (x, y, w, h) = faces[0]
        face = frame[y:y+h, x:x+w]
        face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)
        input_tensor = transform(face_rgb).unsqueeze(0)

        with torch.no_grad():
            emb = model(input_tensor).squeeze().numpy()

        sims = [cosine_similarity(emb, ref) for ref in embeddings]
        max_sim = max(sims)
        print(f"üîç ƒê·ªô t∆∞∆°ng ƒë·ªìng cao nh·∫•t (cosine): {max_sim:.4f}")

picam2.stop()
cv2.destroyAllWindows()
