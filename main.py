import cv2
import numpy as np
import torch
import time
from torchvision import models, transforms
from picamera2 import Picamera2
from numpy.linalg import norm
from pathlib import Path

# ==== C·∫§U H√åNH ====
user_name = "KHOI"
threshold = 0.7
stable_required = 5       # s·ªë l·∫ßn ƒë√∫ng li√™n ti·∫øp ƒë·ªÉ x√°c nh·∫≠n
unstable_limit = 3        # s·ªë l·∫ßn sai li√™n ti·∫øp ƒë·ªÉ reset
check_interval = 0.3      # gi√¢y gi·ªØa 2 l·∫ßn x·ª≠ l√Ω

# ==== ƒê∆Ø·ªúNG D·∫™N ====
base_dir = Path(__file__).resolve().parent / "face_auth"
embedding_path = base_dir / "data" / user_name / "embeddings.npy"
haar_path = base_dir / "haar" / "haarcascade_frontalface_default.xml"

# ==== H√ÄM COSINE SIMILARITY ====
def cosine_similarity(a, b):
    return np.dot(a, b) / (norm(a) * norm(b))

# ==== KI·ªÇM TRA FILE ====
if not embedding_path.exists():
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y {embedding_path}")
    exit()
if not haar_path.exists():
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y {haar_path}")
    exit()

# ==== T·∫¢I D·ªÆ LI·ªÜU ====
known_embeddings = np.load(embedding_path)
face_cascade = cv2.CascadeClassifier(str(haar_path))

model = models.mobilenet_v2(pretrained=True)
model.classifier = torch.nn.Identity()
model.eval()

transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# ==== CAMERA ====
picam2 = Picamera2()
picam2.configure(picam2.create_preview_configuration(main={"format": 'XRGB8888', "size": (640, 480)}))
picam2.start()

cv2.namedWindow("Nh·∫≠n di·ªán realtime", cv2.WINDOW_NORMAL)
cv2.resizeWindow("Nh·∫≠n di·ªán realtime", 600, 350)

print("üöÄ H·ªá th·ªëng s·∫µn s√†ng... Nh·∫•n ESC ƒë·ªÉ tho√°t")

# ==== TR·∫†NG TH√ÅI NH·∫¨N DI·ªÜN ====
stable_count = 0
unstable_count = 0
last_result_is_you = False
last_check = 0
current_label = "ƒêang nh·∫≠n di·ªán..."
current_color = (200, 200, 200)

# ==== V√íNG L·∫∂P CH√çNH ====
while True:
    frame = picam2.capture_array()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)

    for (x, y, w, h) in faces:
        if time.time() - last_check > check_interval:
            last_check = time.time()

            face = frame[y:y+h, x:x+w]
            face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)
            input_tensor = transform(face_rgb).unsqueeze(0)

            with torch.no_grad():
                emb = model(input_tensor).squeeze().numpy()

            sims = [cosine_similarity(emb, ref) for ref in known_embeddings]
            max_sim = max(sims)
            print(f"üìè Cosine similarity: {max_sim:.4f}")

            if max_sim > threshold:
                stable_count += 1
                unstable_count = 0
            else:
                unstable_count += 1
                if unstable_count >= unstable_limit:
                    stable_count = 0

            if stable_count >= stable_required:
                current_label = f"{user_name} ({max_sim:.2f})"
                current_color = (0, 255, 0)
                last_result_is_you = True
            elif stable_count == 0 and last_result_is_you:
                current_label = "Ng∆∞·ªùi l·∫°"
                current_color = (0, 0, 255)
                last_result_is_you = False
            else:
                current_label = "ƒêang ki·ªÉm tra..."
                current_color = (0, 255, 255)

        # V·∫Ω khung
        cv2.rectangle(frame, (x, y), (x+w, y+h), current_color, 2)
        cv2.putText(frame, current_label, (x, y-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, current_color, 2)

    cv2.imshow("Nh·∫≠n di·ªán realtime", frame)
    if cv2.waitKey(1) == 27:
        break

picam2.stop()
cv2.destroyAllWindows()
